{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a model that predicts the result of a running match based on the variables we've already selected.\n",
    "\n",
    "The idea is understand if the variables we've selected are really predictive for the result of a match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%pylab inline\n",
    "\n",
    "import re\n",
    "\n",
    "import gc\n",
    "\n",
    "pd.set_option('display.max_columns', 2000)\n",
    "pd.set_option('display.max_rows', 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DBS_PATH = \"../Bases/\"\n",
    "VARS_PATH = \"../1. Data Preparation/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import the train data and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(DBS_PATH + \"processed_train_games.csv\", index_col=0)\n",
    "test = pd.read_csv(DBS_PATH + \"processed_test_games.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's some extra preprocessing for modeling:\n",
    "* We should train our model with the intermediate moves of the match, as we're going to test it with ongoing matches\n",
    "* As we're playing the match, there are some fields that are unknown during the match\n",
    "    - `opening_ply`\n",
    "    - `last_move_at`\n",
    "    - `turns` => let's remove after exploding the matches\n",
    "    - `black_rating` (once we have created `rating_difference`, and we have `white_rating`)\n",
    "    - `last_move_at` (once we have created `games_delay_in_sec`, and we have `created_at`) => already excluded\n",
    "    - OneHotEncoder should `drop_invariant=True`\n",
    "    - `victory_status` variables\n",
    "\n",
    "_Interesting question:_ Would it be better to do the variable selection with the data in intermediate moves as well? (I think not, as when selecting variables we're really interested in finding the variables that are useful for winning, and the move information is present in each feature. For training, we'll be in an intermediate state, that's why we need preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_columns(df):\n",
    "    victory_status_cols = [x for x in df.columns if 'victory_status' in x]\n",
    "    return df.drop(columns =\n",
    "        victory_status_cols + [\n",
    "            'opening_ply',\n",
    "            'turns',\n",
    "            'black_rating',\n",
    "            'opening_eco_A00',\n",
    "            'moves'\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = remove_columns(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = remove_columns(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explode the matches, and get one line for each turn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pattern = re.compile(\"move{}$\".format(10))\n",
    "#[col for col in train.columns if pattern.search(col)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -326\n",
      "1 -19\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explode_matches(train.head(2)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = []\n",
    "for next_move in range(2, 10):\n",
    "    cols = cols + [col for col in train.columns if \"col{}\".format(next_move)]\n",
    "print(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testar\n",
    "def explode_matches(df):\n",
    "    expld_matches = pd.DataFrame()\n",
    "    \n",
    "    for move in range(1, 100):\n",
    "        df_aux = df.copy()\n",
    "        zero_cols = []\n",
    "        for next_move in range(move+1, 100):\n",
    "            pattern = re.compile(\"move{}$\".format(next_move))\n",
    "            zero_cols = zero_cols + [col for col in train.columns if pattern.search(col)]\n",
    "        df_aux[zero_cols] = 0\n",
    "        expld_matches = pd.concat([expld_matches, df_aux])\n",
    "    \n",
    "    return expld_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = explode_matches(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = explode_matches(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Match result over time\n",
    "    * What are the decisions our model does during a single match?\n",
    "    * It does better at the beginning or at the end? Is there a threshold move which is decisive for our algorithm to determine the result?\n",
    "    \n",
    "* Result at the end\n",
    "    * How well does our model do at the end of the games? (ROC, Precision, Recall, F1)\n",
    "    \n",
    "* Compare with a benchmark\n",
    "    * Engine evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy\n",
    "\n",
    "* Evaluate a match in real time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
